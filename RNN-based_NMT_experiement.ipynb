{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec80bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, glob, subprocess, pandas as pd\n",
    "\n",
    "DATA = \"/root/Course/final_project/nmt_data_jieba_100k\"\n",
    "PY = \"python\"\n",
    "SCRIPT = \"/root/Course/final_project/train_rnn.py\"   # 你的脚本路径\n",
    "\n",
    "SAVE_ROOT = os.path.join(DATA, \"checkpoints\")  # 默认也行，你也可以自定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f686dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = dict(\n",
    "    data_dir=DATA,\n",
    "    vocab_zh=f\"{DATA}/vocab_zh.json\",\n",
    "    vocab_en=f\"{DATA}/vocab_en.json\",\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    emb=256,\n",
    "    hidden=512,\n",
    "    rnn_type=\"lstm\",\n",
    "    lr=3e-4,\n",
    "    seed=42,\n",
    "    decode=\"greedy\",   # 训练期先 greedy，后面单独做 beam 对比\n",
    "    beam_size=4,\n",
    ")\n",
    "\n",
    "experiments = [\n",
    "    dict(**base, attn=\"dot\",     free_running=False),\n",
    "    dict(**base, attn=\"general\", free_running=False),\n",
    "    dict(**base, attn=\"additive\",free_running=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562fbc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /root/Course/final_project/train_rnn.py --data_dir /root/Course/final_project/nmt_data_jieba_100k --vocab_zh /root/Course/final_project/nmt_data_jieba_100k/vocab_zh.json --vocab_en /root/Course/final_project/nmt_data_jieba_100k/vocab_en.json --epochs 10 --batch_size 64 --emb 256 --hidden 512 --rnn_type lstm --attn dot --lr 0.0003 --decode greedy --beam_size 4 --seed 42 --save_root /root/Course/final_project/nmt_data_jieba_100k/checkpoints\n",
      "[Epoch 1] train_loss=5.9477  valid_BLEU4=1.86\n",
      "[Epoch 2] train_loss=4.9657  valid_BLEU4=2.16\n",
      "[Epoch 3] train_loss=4.3846  valid_BLEU4=2.82\n",
      "[Epoch 4] train_loss=3.9308  valid_BLEU4=4.00\n",
      "[Epoch 5] train_loss=3.5847  valid_BLEU4=4.18\n",
      "[Epoch 6] train_loss=3.3108  valid_BLEU4=5.19\n",
      "[Epoch 7] train_loss=3.0839  valid_BLEU4=5.70\n",
      "[Epoch 8] train_loss=2.8908  valid_BLEU4=5.78\n",
      "[Epoch 9] train_loss=2.7207  valid_BLEU4=5.99\n",
      "[Epoch 10] train_loss=2.5702  valid_BLEU4=5.58\n",
      "Saved run dir: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-dot_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42\n",
      "Best: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-dot_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42/best.pt\n",
      "Last: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-dot_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42/last.pt\n",
      "Final(valid) BLEU4 = 5.99 | Final(test) BLEU4 = 5.17\n",
      "python /root/Course/final_project/train_rnn.py --data_dir /root/Course/final_project/nmt_data_jieba_100k --vocab_zh /root/Course/final_project/nmt_data_jieba_100k/vocab_zh.json --vocab_en /root/Course/final_project/nmt_data_jieba_100k/vocab_en.json --epochs 10 --batch_size 64 --emb 256 --hidden 512 --rnn_type lstm --attn general --lr 0.0003 --decode greedy --beam_size 4 --seed 42 --save_root /root/Course/final_project/nmt_data_jieba_100k/checkpoints\n",
      "[Epoch 1] train_loss=5.9647  valid_BLEU4=1.72\n",
      "[Epoch 2] train_loss=4.9565  valid_BLEU4=2.04\n",
      "[Epoch 3] train_loss=4.3808  valid_BLEU4=3.05\n",
      "[Epoch 4] train_loss=3.9211  valid_BLEU4=3.84\n",
      "[Epoch 5] train_loss=3.5551  valid_BLEU4=4.60\n",
      "[Epoch 6] train_loss=3.2676  valid_BLEU4=4.94\n",
      "[Epoch 7] train_loss=3.0366  valid_BLEU4=5.26\n",
      "[Epoch 8] train_loss=2.8407  valid_BLEU4=5.58\n",
      "[Epoch 9] train_loss=2.6689  valid_BLEU4=5.81\n",
      "[Epoch 10] train_loss=2.5160  valid_BLEU4=6.19\n",
      "Saved run dir: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-general_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42\n",
      "Best: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-general_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42/best.pt\n",
      "Last: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-general_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42/last.pt\n",
      "Final(valid) BLEU4 = 6.19 | Final(test) BLEU4 = 5.17\n",
      "python /root/Course/final_project/train_rnn.py --data_dir /root/Course/final_project/nmt_data_jieba_100k --vocab_zh /root/Course/final_project/nmt_data_jieba_100k/vocab_zh.json --vocab_en /root/Course/final_project/nmt_data_jieba_100k/vocab_en.json --epochs 10 --batch_size 64 --emb 256 --hidden 512 --rnn_type lstm --attn additive --lr 0.0003 --decode greedy --beam_size 4 --seed 42 --save_root /root/Course/final_project/nmt_data_jieba_100k/checkpoints\n",
      "[Epoch 1] train_loss=5.9448  valid_BLEU4=1.55\n",
      "[Epoch 2] train_loss=4.9162  valid_BLEU4=2.61\n",
      "[Epoch 3] train_loss=4.2907  valid_BLEU4=3.31\n",
      "[Epoch 4] train_loss=3.8277  valid_BLEU4=4.13\n",
      "[Epoch 5] train_loss=3.4750  valid_BLEU4=3.94\n",
      "[Epoch 6] train_loss=3.1938  valid_BLEU4=5.48\n",
      "[Epoch 7] train_loss=2.9613  valid_BLEU4=5.83\n",
      "[Epoch 8] train_loss=2.7631  valid_BLEU4=6.11\n",
      "[Epoch 9] train_loss=2.5893  valid_BLEU4=6.41\n",
      "[Epoch 10] train_loss=2.4360  valid_BLEU4=6.16\n",
      "Saved run dir: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-additive_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42\n",
      "Best: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-additive_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42/best.pt\n",
      "Last: /root/Course/final_project/nmt_data_jieba_100k/checkpoints/rnn/nmt_data_jieba_100k_rnn-lstm_attn-additive_tf_dec-greedy_bs64_lr0.0003_emb256_h512_seed42/last.pt\n",
      "Final(valid) BLEU4 = 6.41 | Final(test) BLEU4 = 6.18\n"
     ]
    }
   ],
   "source": [
    "def to_cmd(cfg):\n",
    "    cmd = [PY, SCRIPT,\n",
    "           \"--data_dir\", cfg[\"data_dir\"],\n",
    "           \"--vocab_zh\", cfg[\"vocab_zh\"],\n",
    "           \"--vocab_en\", cfg[\"vocab_en\"],\n",
    "           \"--epochs\", str(cfg[\"epochs\"]),\n",
    "           \"--batch_size\", str(cfg[\"batch_size\"]),\n",
    "           \"--emb\", str(cfg[\"emb\"]),\n",
    "           \"--hidden\", str(cfg[\"hidden\"]),\n",
    "           \"--rnn_type\", cfg[\"rnn_type\"],\n",
    "           \"--attn\", cfg[\"attn\"],\n",
    "           \"--lr\", str(cfg[\"lr\"]),\n",
    "           \"--decode\", cfg[\"decode\"],\n",
    "           \"--beam_size\", str(cfg[\"beam_size\"]),\n",
    "           \"--seed\", str(cfg[\"seed\"]),\n",
    "           \"--save_root\", SAVE_ROOT\n",
    "    ]\n",
    "    if cfg.get(\"free_running\", False):\n",
    "        cmd.append(\"--free_running\")\n",
    "    return cmd\n",
    "\n",
    "def run_experiment(cfg):\n",
    "    cmd = to_cmd(cfg)\n",
    "    print(\" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "for cfg in experiments:\n",
    "    run_experiment(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
